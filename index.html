<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Large language models are susceptible to memorizing repeated sequences, posing privacy and copyright concerns. A popular mitigation strategy is to remove memorized information from specific neurons post-hoc. However, such approaches have shown limited success so far. In a controlled setting, we show that the memorization of \emph{natural} sequences (those that resemble linguistically plausible text) become \emph{mechanistically entangled} with general language abilities, thereby becoming challenging to remove post-hoc. In this work, we put forward a new paradigm of \seqtd that promotes isolation of memorization by design. We leverage a sequence identifier to activate a unique set of memorization neurons for each sequence across repetitions. By analyzing the dynamics of learning and forgetting, we argue that \seqtd facilitates clean isolation of memorized content, making it easier to remove without compromising general language capabilities. We implement \seqtd at the billion-parameter and billion-token scale, and observe both effective isolation and strong generalization. To our knowledge, this is the first proof-of-concept on real data demonstrating that simultaneous generalization and isolation is achievable. We open-source our code at http://github.com/grghosal/MemSinks">
  <meta property="og:title" content="Memorization Sinks: Isolating Memorization during LLM Training"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/sink.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Memorization Sinks: Isolating Memorization during LLM Training </title>
  <link rel="icon" type="image/x-icon" href="static/images/sink.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Memorization Sinks: Isolating Memorization during LLM Training            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Gaurav R. Ghosal</a>, 
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Pratyush Maini</a>, 
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Aditi Raghunathan</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Carnegie Mellon University<br>ICML 2025</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/MemSinksFig.png" alt="Teaser Image" class="teaser-image">
      <h2 class="subtitle has-text-centered">
      Standard training of LLMs can lead to memorization being arbitrarily distributed across the model. As a result, removing it is costly and often degrades general capabilites. Our training technique, <strong>MemSinks</strong>, maintains a set of <it> sink neurons</it> to implement memorization. These memorization sinks are <it> removable by design</it>, enabling straightforward downstream unlearning.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large language models are susceptible to memorizing repeated sequences, posing privacy and copyright concerns. A popular mitigation strategy is to remove memorized information from specific neurons post-hoc. However, such approaches have shown limited success so far. In a controlled setting, we show that the memorization of \emph{natural} sequences (those that resemble linguistically plausible text) become \emph{mechanistically entangled} with general language abilities, thereby becoming challenging to remove post-hoc. In this work, we put forward a new paradigm of \seqtd that promotes isolation of memorization by design. We leverage a sequence identifier to activate a unique set of memorization neurons for each sequence across repetitions. By analyzing the dynamics of learning and forgetting, we argue that \seqtd facilitates clean isolation of memorized content, making it easier to remove without compromising general language capabilities. We implement \seqtd at the billion-parameter and billion-token scale, and observe both effective isolation and strong generalization. To our knowledge, this is the first proof-of-concept on real data demonstrating that simultaneous generalization and isolation is achievable. We open-source our code at <a></a>http://github.com/grghosal/MemSinks</p>          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->
<!-- Paper poster -->
<section class="hero is-small is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">The Limitations of Post-Hoc Memorization Removal</h2>
      <div class="content has-text-justified">
        <p>
          Existing work on removing memorization hinges on the assumption that we can clearly delineate memorization from other LLM capabilities. Through a controlled study, we show that memorization is not always cleanly seperated from general language capabilities. This is particularly the case for memorized sequences resembling natural text (i.e. books, articles, etc). On the other hand, highly atypical memorized strings (i.e. random token sequences) can be naturally seperated. </p>

        </div>
        <center>
          <img src="static/images/IGInv.png" alt="Teaser Image" class="teaser-image" width  = "400px">
          <img src="static/images/HCInv.png" alt="Teaser Image" class="teaser-image" width  = "410px">
          </center>
          <p>
            <center>
              <b><i>Fig 2: Shortcomings of Post-Hoc Methods.</i></b> We show that state-of-the-art techniques for removing memorization induce a <it>tradeoff</it> between getting rid of memorization and preserving the model's general capabilities. This tradeoff is particularly amplified when memorized sequences consist of repeated, natural text. 
            </center>
          </p>
      </div>
    </div>
  </section>
<!--End paper poster -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">MemSinks: Isolating Memorization By Design</h2>
      <div class="content has-text-justified">
        <p>
          Given the shortcomings of removing memorization post-hoc, we next turn our attention to explicitly training models to enable the removal of memorization. We propose a new training paradigm, <strong>MemSinks</strong> to simultaneously achieve two goals:
          <center>
          <div style="background-color: lightblue;margin: 0px;padding-top: 10px;padding-bottom: 10px;width: 60%">
          
          <ul style="list-style-position: inside;text-align: left; list-style-type: none">
            <li>&#9989;  <strong>Isolate Memorization</strong>: Memorization should be stored in a known and removable set of neurons.</li>
            <li>&#9989; <strong>Preserve Cross-Sequence Learning</strong>: The model should learn general capabilities from all data.</li>
          </ul> 
          
          </div>
        </center>
        </p>
          We achieve this by setting aside a set of <i>memorization sink neurons</i> in the transformer MLP layers. During training, a determinisstic subset of these sink neurons are activated on any sequence (using sequence-specific identifiers), alongside a set of <i>general neurons</i> that are activated on all sequences. Downstream, removing memorization sinks yields a model comparable in general capabilities, but without memorization! Importantly, we see that MemSinks achieves a better tradeoff between <i> removing memorization</i> and preserving general language capabilities.
          </p>
          <center>
            <img src="static/images/MemSinksVal.png" alt="Teaser Image" class="teaser-image" width  = "400px">
            <img src="static/images/MemSinksMem.png" alt="Teaser Image" class="teaser-image" width  = "400px">
            <img src="static/images/SeqTiedTradeoffInv.png" alt="Teaser Image" class="teaser-image" width  = "410px">
            </center>



        </div>
        <p>
          <center>
          <b><i>Fig 2: Performance of MemSinks.</i></b> (Left) MemSinks achieves comparable validation loss as standard training. (Center) MemSinks memorizes significantly less than standard training. (Right) MemSinks achieves a better tradeoff between removing memorization and preserving general capabilities than post-hoc methods.
          </center>
        </p>
      </div>

        </section>
        
    </div>
  </section>

    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title">Scaling MemSinks to 1B Parameter Model</h2>
          <div class="content has-text-justified">
            <p>
            Based on our preliminary results, we deployed MemSinks when training 360M and 1.7 B parameter models on a mixture of Wikipedia and SlimPajama data. We consider a setting where we wish to upsample the relatively rare Wikipedia data (to improve validation loss on Wikipedia documents). Upsampling the training Wikipedia data leads to a model that memorizes less than standard training, but is still able to generalize to Wikipedia documents.  Upsampling the training Wikipedia documents results in memorization, as seen in the gap betwen validation and training loss in the training curves below. We see that MemSinks enables us to mitigate this memorization while still improving Wikipedia validation loss using the repeated documents (outperforming deduplicated standard training).          
            </p>
              </p>
              <center>
                <img src="static/images/MemSinks17B.png" alt="Teaser Image" class="teaser-image" width  = "400px">
                <img src="static/images/MemSinks360.png" alt="Teaser Image" class="teaser-image" width  = "400px">
                </center>
    
    
    
            </div>
            <p>
              <center>
              <b><i>Fig 3: Scaling MemSinks to 1B Parameter Model.</i></b> Training loss curves for 1.7B (left) and 360M (right) parameter models trained on a mixture of Wikipedia and SlimPajama data.
              </center>
            </p>
          </div>
    
            </section>
            
        </div>
      </section>
<!--End paper poster -->









<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{
        ghosal2025memorization,
        title={Memorization Sinks: Isolating Memorization during {LLM} Training},
        author={Gaurav Rohit Ghosal and Pratyush Maini and Aditi Raghunathan},
        booktitle={Forty-second International Conference on Machine Learning},
        year={2025},
        url={https://openreview.net/forum?id=sRJrMPu5Uu}
        }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
